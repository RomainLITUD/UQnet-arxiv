{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import shapely\n",
    "from shapely.geometry import LineString\n",
    "from matplotlib.path import Path\n",
    "from shapely import geometry, ops\n",
    "from scipy.sparse import csr_matrix\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d189f",
   "metadata": {},
   "source": [
    "### This notebook tells how to generate drivable area masks.\n",
    "\n",
    "- This is optional.\n",
    "- We read the prepared dataset from <code>data_generator</code> notebook and run the following blocks sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22162ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = np.meshgrid(np.arange(-22.5,23,1),np.arange(-11.5, 75, 1))\n",
    "mesh = np.stack([x.T,y.T],2)\n",
    "mesh = mesh.reshape(-1, 2)\n",
    "mesh.shape\n",
    "def generate_mask(polylines, nbs, width, mesh, y):\n",
    "    centerlines = np.concatenate([polylines[:nbs,:,:2], polylines[:nbs,-1:,2:4]], 1)\n",
    "    splines = [LineString(polyline) for polyline in centerlines]\n",
    "    w = width[:nbs]\n",
    "    leftBound = [spline.parallel_offset(w_, 'left', resolution=6) for w_, spline in zip(w, splines)]\n",
    "    rightBound = [spline.parallel_offset(w_, 'right', resolution=6) for w_, spline in zip(w, splines)]\n",
    "    \n",
    "    polygons = []\n",
    "    \n",
    "    for i in range(len(splines)):\n",
    "        if leftBound[i].geom_type == 'LineString':\n",
    "            left = list(leftBound[i].coords)\n",
    "            print(left)\n",
    "        else:\n",
    "            le = [list(element.coords) for element in list(leftBound[i].geoms)]#list(leftBound.geoms)\n",
    "            left = sum(le, [])#list(itertools.chain.from_iterable(le))\n",
    "        if rightBound[i].geom_type == 'LineString':\n",
    "            right = list(rightBound[i].coords)\n",
    "        else:\n",
    "            ri = [list(element.coords) for element in list(rightBound[i].geoms)]#list(leftBound.geoms)\n",
    "            right = sum(ri, [])#list(itertools.chain.from_iterable(ri))\n",
    "        polygons.append(Path(left+right))\n",
    "    mask_list = [p.contains_points(mesh) for p in polygons]\n",
    "    mask = np.any(np.array(mask_list),0)\n",
    "    mask = mask.reshape(46, 87)\n",
    "    \n",
    "    cx, cy = int(y[0]+23), int(y[1]+12)\n",
    "    if mask[cx, cy]:\n",
    "        cont = 1\n",
    "    else:\n",
    "        cont = 0\n",
    "    return mask, cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bdd502",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This block is for the training set\n",
    "'''\n",
    "M = []\n",
    "N = []\n",
    "W = []\n",
    "Y = []\n",
    "for i in range(1,5):\n",
    "    data = np.load('./interaction_merge/train'+str(i)+'.npz', allow_pickle=True)\n",
    "    M.append(data['maps'])\n",
    "    N.append(data['nbsplines'])\n",
    "    W.append(data['lanefeature'])\n",
    "    Y.append(data['intention'])\n",
    "M = np.concatenate(M,0)\n",
    "N = np.concatenate(N,0)\n",
    "W = np.concatenate(W,0)\n",
    "Y = np.concatenate(Y,0)\n",
    "\n",
    "S = []\n",
    "C = []\n",
    "for i in tqdm(range(len(M))):\n",
    "    gc.disable()\n",
    "    s, c = generate_mask(M[i], N[i], W[i].toarray()[...,0], mesh, Y[i]) #this is only for training set and validation set\n",
    "    S.append(csr_matrix(s))\n",
    "    C.append(c)\n",
    "    gc.enable()\n",
    "S = np.array(S)\n",
    "C = np.array(C)\n",
    "\n",
    "np.savez_compressed('./interaction_merge/mask_train', mask=S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e90ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this is for the validation sets (val/val_all)\n",
    "'''\n",
    "data = np.load('./interaction_merge/val.npz', allow_pickle=True) # can be changed to vall_all as well\n",
    "M = data['maps']\n",
    "N = data['nbsplines']\n",
    "W = data['lanefeature']\n",
    "Y = data['intention']\n",
    "\n",
    "S = []\n",
    "C = []\n",
    "for i in tqdm(range(len(M))):\n",
    "    gc.disable()\n",
    "    s, c = generate_mask(M[i], N[i], W[i].toarray()[...,0], mesh, Y[i]) #this is only for training set and validation set\n",
    "    S.append(csr_matrix(s))\n",
    "    C.append(c)\n",
    "    gc.enable()\n",
    "S = np.array(S)\n",
    "C = np.array(C)\n",
    "\n",
    "np.savez_compressed('./interaction_merge/mask_val', mask=S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c55071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is for the testing set\n",
    "'''\n",
    "data = np.load('./interaction_merge/test.npz', allow_pickle=True) \n",
    "M = data['maps']\n",
    "N = data['nbsplines']\n",
    "W = data['lanefeature']\n",
    "\n",
    "S = []\n",
    "C = []\n",
    "for i in tqdm(range(len(M))):\n",
    "    gc.disable()\n",
    "    s, c = generate_mask(M[i], N[i], W[i].toarray()[...,0], mesh, [0,0])\n",
    "    S.append(csr_matrix(s))\n",
    "    C.append(c)\n",
    "    gc.enable()\n",
    "S = np.array(S)\n",
    "C = np.array(C)\n",
    "\n",
    "np.savez_compressed('./interaction_merge/mask_test', mask=S)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
